# app/tasks/post_tasks.py
import asyncio
from datetime import datetime, timedelta
from sqlalchemy import select
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import selectinload

from app.celery_app import celery_app
from app.database import async_session
from app.models import NewsItem, Post, PostStatus, Keyword
from app.logger import logger
from app.ai.openai_client import openai_client

MAX_RETRIES = 3
MAX_PER_RUN = 3
MAX_DELETE_PER_RUN = 20
OPENAI_DELAY = 0.5  # –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ OpenAI
OPENAI_KEYWORD_DELAY = 20  # —Å–µ–∫—É–Ω–¥–∞, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å rate limit (RPM)


# =========================
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤
# =========================
@celery_app.task(name="generate_posts")
def generate_posts():
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ö –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤.

    """
    async def _main():
        async with async_session() as session:
            news_list = (await session.execute(select(NewsItem))).scalars().all()
            generated_count = 0

            for news in news_list:
                if generated_count >= MAX_PER_RUN:
                    break

                post = (await session.execute(select(Post).where(Post.news_id == news.id))).scalar_one_or_none()

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ
                if post and post.status == PostStatus.published:
                    continue

                # –£–¥–∞–ª—è–µ–º failed –ø–æ—Å—Ç—ã, –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç retry
                if post and post.status == PostStatus.failed and post.retry_count >= MAX_RETRIES:
                    logger.info(f"üóë –£–¥–∞–ª—è–µ–º failed –ø–æ—Å—Ç –∏ –Ω–æ–≤–æ—Å—Ç—å: {news.id}")
                    await session.delete(post)
                    await session.delete(news)
                    continue

                text_source = news.raw_text or news.summary
                try:
                    generated_text = await openai_client.generate_text(text_source)
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {news.id}: {e}")
                    if post:
                        post.retry_count += 1
                        post.error_message = str(e)
                        if post.retry_count >= MAX_RETRIES:
                            post.status = PostStatus.failed
                    else:
                        post = Post(
                            news_id=news.id,
                            status=PostStatus.failed,
                            retry_count=1,
                            error_message=str(e)
                        )
                        session.add(post)
                    continue

                if not generated_text or not generated_text.strip():
                    logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç OpenAI –¥–ª—è {news.id}")
                    if post:
                        post.retry_count += 1
                        post.error_message = "Empty OpenAI response"
                        if post.retry_count >= MAX_RETRIES:
                            post.status = PostStatus.failed
                    else:
                        post = Post(
                            news_id=news.id,
                            status=PostStatus.failed,
                            retry_count=1,
                            error_message="Empty OpenAI response"
                        )
                        session.add(post)
                    continue

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
                if post:
                    post.generated_text = generated_text
                    post.status = PostStatus.new
                    post.retry_count = 0
                    post.error_message = None
                    logger.info(f"‚ôªÔ∏è –û–±–Ω–æ–≤–ª—ë–Ω –ø–æ—Å—Ç –¥–ª—è {news.id}")
                else:
                    new_post = Post(
                        news_id=news.id,
                        generated_text=generated_text,
                        status=PostStatus.new,
                        retry_count=0,
                        error_message=None
                    )
                    session.add(new_post)
                    logger.info(f"üÜï –°–æ–∑–¥–∞–Ω –ø–æ—Å—Ç –¥–ª—è {news.id}")

                generated_count += 1
                await asyncio.sleep(OPENAI_DELAY)

            await session.commit()
            return generated_count

    try:
        count = asyncio.run(_main())
    except RuntimeError:
        # fallback –¥–ª—è Windows
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        count = loop.run_until_complete(_main())

    logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–æ—Å—Ç–æ–≤: {count}")
    return count


# =========================
# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö failed –ø–æ—Å—Ç–æ–≤
# =========================
@celery_app.task(name="cleanup_old_failed_posts")
def cleanup_old_failed_posts(days: int = 7):
    """
    –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö failed –ø–æ—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å.

    """
    async def _main():
        async with async_session() as session:
            cutoff = datetime.utcnow() - timedelta(days=days)
            posts = (await session.execute(
                select(Post).where(
                    Post.status == PostStatus.failed,
                    Post.created_at < cutoff
                )
            )).scalars().all()

            deleted_count = 0
            for i, post in enumerate(posts):
                if i >= MAX_DELETE_PER_RUN:
                    break
                if post.news:
                    await session.delete(post.news)
                await session.delete(post)
                deleted_count += 1

            await session.commit()
            return deleted_count

    try:
        count = asyncio.run(_main())
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        count = loop.run_until_complete(_main())

    logger.info(f"üóë –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö failed –ø–æ—Å—Ç–æ–≤: {count} —É–¥–∞–ª–µ–Ω–æ")
    return count


# =========================
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (—Ç–µ–≥–æ–≤) –¥–ª—è –ø–æ—Å—Ç–æ–≤
# =========================
@celery_app.task(name="generate_post_keywords")
def generate_post_keywords():
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –ø–æ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Ç–µ–∫—Å—Ç–∞.

    """
    async def _main():
        async with async_session() as session:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç—ã –∏ –∏—Ö keywords –∑–∞—Ä–∞–Ω–µ–µ (selectinload)
            posts = (await session.execute(
                select(Post)
                .options(selectinload(Post.keywords))
                .where(Post.status.in_([PostStatus.new, PostStatus.generated]))
            )).scalars().all()

            updated_count = 0

            for post in posts:
                if post.keywords:
                    logger.info(f"üü° –ü—Ä–æ–ø—É—â–µ–Ω –ø–æ—Å—Ç {post.id}, —Ç–µ–≥–∏ —É–∂–µ –µ—Å—Ç—å")
                    continue

                text_for_analysis = post.generated_text or (post.news.summary if post.news else "")
                if not text_for_analysis.strip():
                    logger.info(f"üü° –ü—Ä–æ–ø—É—â–µ–Ω –ø–æ—Å—Ç {post.id}, –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç")
                    continue

                keywords = []
                for attempt in range(MAX_RETRIES):
                    try:
                        keywords = await openai_client.generate_keywords(text_for_analysis)
                        if keywords:
                            break  # —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–∏–ª–∏
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{MAX_RETRIES} –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–≥–æ–≤ –¥–ª—è {post.id} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                        await asyncio.sleep(OPENAI_KEYWORD_DELAY)  # –∂–¥—ë–º –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º

                if not keywords:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–≥–∏ –¥–ª—è –ø–æ—Å—Ç–∞ {post.id} –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")
                    continue

                for word in keywords:
                    try:
                        keyword_obj = (await session.execute(
                            select(Keyword).where(Keyword.word == word)
                        )).scalar_one_or_none()

                        if not keyword_obj:
                            keyword_obj = Keyword(word=word)
                            session.add(keyword_obj)
                            await session.flush()  # –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ ID

                        if keyword_obj not in post.keywords:
                            post.keywords.append(keyword_obj)
                    except IntegrityError:
                        await session.rollback()
                        continue

                updated_count += 1
                logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ç–µ–≥–∏ –¥–ª—è –ø–æ—Å—Ç–∞ {post.id}: {keywords}")
                await asyncio.sleep(OPENAI_KEYWORD_DELAY)  # —Å–æ–±–ª—é–¥–∞–µ–º rate limit

            await session.commit()
            return updated_count

    try:
        count = asyncio.run(_main())
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        count = loop.run_until_complete(_main())

    logger.info(f"üè∑ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ç–µ–≥–æ–≤ –¥–ª—è –ø–æ—Å—Ç–æ–≤: {count}")
    return count
