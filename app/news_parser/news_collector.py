# app/news_parser/news_collector.py
import asyncio
from typing import List

from app.logger import logger
from app.config import settings
from app.news_parser import parser_habr, parser_rbk, parser_telegram
from app.api.schemas import ParsedNewsSchema


async def collect_news(limit_telegram: int = 50) -> List[ParsedNewsSchema]:
    """
    –°–±–æ—Ä –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π —Å Habr, RBK –∏ Telegram.
    """

    logger.info("üöÄ –°—Ç–∞—Ä—Ç —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

    tasks = [
        parser_habr.parse_news_habr_site(),
        parser_rbk.parse_news_rbk_site(),
        parser_telegram.parse_telegram_channel(limit=limit_telegram),
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    raw_news = []
    for source_news in results:
        if isinstance(source_news, Exception):
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source_news}")
            continue
        raw_news.extend(source_news)

    logger.info(f"–°–æ–±—Ä–∞–Ω–æ –≤—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π (–¥–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏): {len(raw_news)}")

    # =========================
    # –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pydantic
    # =========================
    validated_news: List[ParsedNewsSchema] = []
    for item in raw_news:
        try:
            validated = ParsedNewsSchema.model_validate(item)
            validated_news.append(validated)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –ø—Ä–æ—à–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é): {e}")

    logger.info(f"–ü–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {len(validated_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # =========================
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ URL
    # =========================
    seen_urls = set()
    unique_news: List[ParsedNewsSchema] = []
    for news in validated_news:
        if news.url in seen_urls:
            continue
        seen_urls.add(news.url)
        unique_news.append(news)

    logger.info(f"–ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(unique_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # =========================
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    # =========================
    keywords = settings.keywords_list
    if keywords:
        filtered_news = []
        for news in unique_news:
            text = f"{news.title} {news.summary}".lower()
            if any(word.lower() in text for word in keywords):
                filtered_news.append(news)
        logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {len(filtered_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    else:
        filtered_news = unique_news

    # =========================
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ
    # =========================
    filtered_news.sort(
        key=lambda x: x.published_at or "",
        reverse=True
    )

    return filtered_news
