# app/news_parser/news_collector.py
import asyncio
from typing import List
from datetime import datetime

from app.logger import logger
from app.config import settings
from app.news_parser import parser_habr, parser_rbk, parser_telegram
from app.api.schemas import ParsedNewsSchema


async def collect_news(limit_telegram: int = 50) -> List[ParsedNewsSchema]:
    """
    –°–±–æ—Ä, –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π —Å Habr, RBK –∏ Telegram.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö ParsedNewsSchema.
    """

    logger.info("üöÄ –°—Ç–∞—Ä—Ç —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

    # =========================
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–æ–≤
    # =========================
    tasks = [
        parser_habr.parse_news_habr_site(),
        parser_rbk.parse_news_rbk_site(),
        parser_telegram.parse_telegram_channel(limit=limit_telegram),
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # =========================
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    # =========================
    raw_news = []
    for source_news in results:
        if isinstance(source_news, Exception):
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source_news}")
            continue
        raw_news.extend(source_news)

    logger.info(f"–°–æ–±—Ä–∞–Ω–æ –≤—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π (–¥–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏): {len(raw_news)}")

    # =========================
    # –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pydantic
    # =========================
    validated_news: List[ParsedNewsSchema] = []
    for item in raw_news:
        try:
            validated = ParsedNewsSchema.model_validate(item)
            validated_news.append(validated)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –ø—Ä–æ—à–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é): {e}")

    logger.info(f"–ü–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {len(validated_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # =========================
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ URL
    # =========================
    seen_urls = set()
    unique_news: List[ParsedNewsSchema] = []
    for news in validated_news:
        if news.url in seen_urls:
            continue
        seen_urls.add(news.url)
        unique_news.append(news)

    logger.info(f"–ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(unique_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # =========================
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    # =========================
    keywords = [kw.lower() for kw in settings.keywords_list] if settings.keywords_list else []
    if keywords:
        filtered_news = [
            news for news in unique_news
            if any(word in f"{news.title} {news.summary}".lower() for word in keywords)
        ]
        logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {len(filtered_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    else:
        filtered_news = unique_news

    # =========================
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    # =========================
    filtered_news.sort(
        key=lambda x: x.published_at or datetime.min,
        reverse=True
    )

    return filtered_news


# =========================
# –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
# =========================
async def main():
    news = await collect_news(limit_telegram=20)
    for idx, item in enumerate(news, 1):
        print(f"{idx}. [{item.source_type}] {item.title} ({item.published_at})")
        print(f"   {item.url}\n")
        print(f"–ö—Ä–∞—Ç–∫–æ: {item.summary}\n")


if __name__ == "__main__":
    asyncio.run(main())
