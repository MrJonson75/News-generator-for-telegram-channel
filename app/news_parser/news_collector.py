# app/news_parser/news_collector.py
import asyncio
from typing import List
from datetime import datetime

from sqlalchemy import select

from app.logger import logger
from app.config import settings
from app.news_parser import parser_habr, parser_rbk, parser_telegram
from app.api.schemas import ParsedNewsSchema
from app.database import async_session
from app.models import Source


async def collect_news(limit_telegram: int = 50) -> List[ParsedNewsSchema]:
    """
    –°–±–æ—Ä, –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ –±–∞–∑–∞ –ø—É—Å—Ç–∞.
    """

    logger.info("üöÄ –°—Ç–∞—Ä—Ç —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

    # -------------------------
    # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –±–∞–∑—ã
    # -------------------------
    async with async_session() as session:
        result = await session.execute(select(Source).where(Source.enabled == True))
        sources = result.scalars().all()

        # –ï—Å–ª–∏ –±–∞–∑–∞ –ø—É—Å—Ç–∞ ‚Äî —Å–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å–∏ –∏–∑ config
        if not sources:
            logger.info("‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ –±–∞–∑–µ, —Å–æ–∑–¥–∞—ë–º –∏–∑ config")
            default_sources = [
                {
                    "name": "habr.com",
                    "type": "site",
                    "url": settings.habr_url,
                    "enabled": True,
                },
                {
                    "name": "rbc.ru",
                    "type": "site",
                    "url": settings.rbc_url,
                    "enabled": True,
                },
                {
                    "name": settings.telegram_news_channel,
                    "type": "tg",
                    "url": f"https://t.me/{settings.telegram_news_channel}",
                    "enabled": True,
                },
            ]
            for src in default_sources:
                session.add(Source(**src))
            await session.commit()

            # –ø–µ—Ä–µ—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            result = await session.execute(select(Source).where(Source.enabled == True))
            sources = result.scalars().all()

    if not sources:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
        return []

    # -------------------------
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–µ—Ä–æ–≤ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏
    # -------------------------
    tasks = []
    for src in sources:
        if not src.enabled:
            continue
        if src.type == "site" and "habr" in src.name.lower():
            tasks.append(parser_habr.parse_news_habr_site())
        elif src.type == "site" and "rbc" in src.name.lower():
            tasks.append(parser_rbk.parse_news_rbk_site())
        elif src.type == "tg":
            tasks.append(parser_telegram.parse_telegram_channel(limit=limit_telegram))

    if not tasks:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –∑–∞–¥–∞—á –¥–ª—è –ø–∞—Ä—Å–µ—Ä–æ–≤")
        return []

    # -------------------------
    # –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    # -------------------------
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # -------------------------
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    # -------------------------
    raw_news = []
    for source_news in results:
        if isinstance(source_news, Exception):
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source_news}")
            continue
        raw_news.extend(source_news)

    logger.info(f"–°–æ–±—Ä–∞–Ω–æ –≤—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π (–¥–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏): {len(raw_news)}")

    # -------------------------
    # –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pydantic
    # -------------------------
    validated_news: List[ParsedNewsSchema] = []
    for item in raw_news:
        try:
            validated = ParsedNewsSchema.model_validate(item)
            validated_news.append(validated)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–Ω–µ –ø—Ä–æ—à–ª–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—é): {e}")

    logger.info(f"–ü–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {len(validated_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # -------------------------
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ URL
    # -------------------------
    seen_urls = set()
    unique_news: List[ParsedNewsSchema] = []
    for news in validated_news:
        if news.url in seen_urls:
            continue
        seen_urls.add(news.url)
        unique_news.append(news)

    logger.info(f"–ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(unique_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # -------------------------
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    # -------------------------
    keywords = [kw.lower() for kw in settings.keywords_list] if settings.keywords_list else []
    if keywords:
        filtered_news = [
            news for news in unique_news
            if any(word in f"{news.title} {news.summary}".lower() for word in keywords)
        ]
        logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {len(filtered_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    else:
        filtered_news = unique_news

    # -------------------------
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
    # -------------------------
    filtered_news.sort(key=lambda x: x.published_at or datetime.min, reverse=True)

    return filtered_news


# =========================
# –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
# =========================
async def main():
    news = await collect_news(limit_telegram=20)
    for idx, item in enumerate(news, 1):
        print(f"{idx}. [{item.source_type}] {item.title} ({item.published_at})")
        print(f"   {item.url}\n")
        print(f"–ö—Ä–∞—Ç–∫–æ: {item.summary}\n")


if __name__ == "__main__":
    asyncio.run(main())
