# app/news_parser/news_collector.py
import asyncio
from typing import List, Dict
from app.logger import logger
from app.config import settings
from app.news_parser import parser_habr, parser_rbk, parser_telegram


async def collect_news(limit_telegram: int = 50) -> List[Dict]:
    """
    –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å Habr, RBC –∏ Telegram.

    :param limit_telegram: —Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π Telegram –ø–∞—Ä—Å–∏—Ç—å
    :return: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    """
    logger.info("üöÄ –°—Ç–∞—Ä—Ç —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π
    tasks = [
        parser_habr.parse_news_habr_site(),
        parser_rbk.parse_news_rbk_site(),
        parser_telegram.parse_telegram_channel(limit=limit_telegram),
    ]

    # –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–æ–≤ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    all_news: List[Dict] = []
    for source_news in results:
        if isinstance(source_news, Exception):
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source_news}")
            continue
        all_news.extend(source_news)

    logger.info(f"–°–æ–±—Ä–∞–Ω–æ –≤—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π (–¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏/–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏): {len(all_news)}")

    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ URL
    seen_urls = set()
    unique_news = []
    for news in all_news:
        url = news.get("url")
        if not url or url in seen_urls:
            continue
        seen_urls.add(url)
        unique_news.append(news)

    logger.info(f"–ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(unique_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    keywords = settings.news_keywords
    if keywords:
        filtered_news = []
        for news in unique_news:
            text = f"{news.get('title','')} {news.get('summary','')}".lower()
            if any(word in text for word in keywords):
                filtered_news.append(news)
        logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {len(filtered_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    else:
        filtered_news = unique_news

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (—Å–Ω–∞—á–∞–ª–∞ –Ω–æ–≤—ã–µ)
    filtered_news.sort(key=lambda x: x.get("published_at") or "", reverse=True)

    return filtered_news


# –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
async def main():
    news = await collect_news(limit_telegram=20)
    for idx, item in enumerate(news, 1):
        print(f"{idx}. [{item['source']}] {item['title']} ({item['published_at']})")
        print(f"   {item['url']}\n")
        print(f"–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {item['summary']}\n")


if __name__ == "__main__":
    asyncio.run(main())
