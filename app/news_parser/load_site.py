# app/news_parser/load_site.py
import httpx
from app.logger import logger
from app.utils.rate_limit import random_delay


async def fetch_html(url: str, retries: int = 3) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ URL —Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ–º –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö."""
    for attempt in range(1, retries + 1):
        try:
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
            await random_delay(1.5, 4.0)

            logger.info(f"üåê –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url} (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å —Ç–∞–π–º–∞—É—Ç–æ–º 15 —Å–µ–∫—É–Ω–¥
            async with httpx.AsyncClient(timeout=15) as client:
                response = await client.get(url)
                response.raise_for_status()
                return response.text

        except httpx.HTTPStatusError as e:
            status = e.response.status_code

            if status == 404:
                logger.error(f"‚ùå –°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {url}")
                return ""

            if status in (429, 500, 502, 503):
                logger.warning(
                    f"‚ö†Ô∏è HTTP {status} –¥–ª—è {url}, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ –ø–∞—É–∑—É"
                )
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
                await random_delay(5, 12)
                continue

            logger.exception(f"‚ùå HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
            raise

        except httpx.RequestError:
            logger.warning(f"‚ö†Ô∏è –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}")
            await random_delay(5, 10)
            continue

    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫: {url}")
    return ""
