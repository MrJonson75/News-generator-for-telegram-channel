# app/ai/openai_client.py
import aiohttp
import asyncio
from typing import List
from app.config import settings
from app.logger import logger


class RateLimitError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ rate limit OpenAI (HTTP 429)"""
    pass


class OpenAIClient:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è OpenAI API (GPT-4o-mini) —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–∫—Å–∏ —á–µ—Ä–µ–∑ aiohttp.
    """

    BASE_URL = "https://api.openai.com/v1"

    def __init__(self, api_key: str = None, proxy: str = None):
        self.api_key = api_key or settings.openai_api_key
        self.proxy = proxy or settings.openai_proxy

        if not self.api_key:
            logger.error("‚ùå OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω!")
        else:
            logger.info("ü§ñ OpenAI –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            if self.proxy:
                logger.info(f"üåê –ü—Ä–æ–∫—Å–∏ –∑–∞–¥–∞–Ω: {self.proxy}")

    def _format_proxy(self) -> str | None:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ø—Ä–æ–∫—Å–∏ –≤ —Ñ–æ—Ä–º–∞—Ç aiohttp: http://user:pass@host:port
        """
        if not self.proxy:
            return None
        try:
            if "@" in self.proxy:
                auth, hostport = self.proxy.split("@")
                user, password = auth.split(":")
                host, port = hostport.split(":")
                return f"http://{user}:{password}@{host}:{port}"
            else:
                return f"http://{self.proxy}"
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ –ø—Ä–æ–∫—Å–∏ {self.proxy}: {e}")
            return None

    async def _request(self, endpoint: str, payload: dict, timeout: int = 30) -> dict:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API
        """
        if not self.api_key:
            raise RuntimeError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω")

        proxy_url = self._format_proxy()

        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.BASE_URL}{endpoint}",
                json=payload,
                headers={"Authorization": f"Bearer {self.api_key}"},
                proxy=proxy_url,
                timeout=aiohttp.ClientTimeout(total=timeout),
            ) as response:

                text = await response.text()

                if response.status == 429:
                    logger.warning(f"‚è≥ OpenAI rate limit: {text}")
                    raise RateLimitError(text)

                if response.status != 200:
                    logger.error(f"‚ùå OpenAI API {response.status}: {text}")
                    raise RuntimeError(f"OpenAI error {response.status}: {text}")

                return await response.json()

    async def generate_text(
        self,
        news_text: str,
        model: str = "gpt-4o-mini",
        max_tokens: int = 300,
        temperature: float = 0.7,
    ) -> str:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenAI GPT-4o-mini.
        """
        prompt = f"{settings.openai_prompt}\n\n{news_text}"

        payload = {
            "model": model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": temperature,
        }

        try:
            data = await self._request("/chat/completions", payload)
            return data["choices"][0]["message"]["content"].strip()
        except RateLimitError:
            raise
        except Exception as e:
            logger.exception(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ OpenAI: {e}")
            raise

    async def generate_keywords(self, text: str, max_keywords: int = 4) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenAI.
        """
        prompt = (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ —Å–æ—Å—Ç–∞–≤—å —Å–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤-—Ç–µ–≥–æ–≤ "
            f"–Ω–µ –±–æ–ª—å—à–µ {max_keywords}. "
            "–¢–µ–≥–∏ –¥–æ–ª–∂–Ω—ã –æ—Ç—Ä–∞–∂–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã, —Å—É—â–Ω–æ—Å—Ç–∏ –∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏.\n\n"
            f"{text}\n\n"
            "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ —Ç–µ–≥–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é."
        )

        response = await self.generate_text(prompt, max_tokens=100, temperature=0.3)

        keywords = [word.strip() for word in response.split(",") if word.strip()]
        return keywords[:max_keywords]

    async def health_client(self) -> dict:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OpenAI API —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω).
        """
        if not self.api_key:
            return {"status": "error", "detail": "OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω"}

        proxy_url = self._format_proxy()

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.BASE_URL}/models",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                    proxy=proxy_url,
                    timeout=aiohttp.ClientTimeout(total=5),
                ) as response:
                    if response.status == 200:
                        return {"status": "ok"}
                    else:
                        text = await response.text()
                        return {"status": "error", "detail": f"HTTP {response.status}: {text}"}
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ OpenAI: {e}")
            return {"status": "error", "detail": str(e)}


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç
openai_client = OpenAIClient()
