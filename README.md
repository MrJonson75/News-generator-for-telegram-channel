## Как все работает.

---

### 1. Механика работы парсера и взаимодействие с базой данных

Система парсинга новостей устроена модульно и работает через Celery-задачи. Основной парсер `parse_and_save_news` запускается по расписанию (например, каждые 30 минут) и собирает новости с разных источников: Habr, RBC и Telegram. Источники динамически определяются из базы данных `Source`: если в столбце `enabled` стоит `True`, соответствующий парсер запускается; если `False` — источник пропускается. При первом запуске, если база пуста, источники подгружаются из конфигурации и создаются автоматически. Каждая собранная новость валидируется через Pydantic (`ParsedNewsSchema`), фильтруется по ключевым словам и дедуплицируется по URL. После этого новости сохраняются в таблицу `NewsItem`, а новые источники — в `Source` с флагом `enabled=True`. Такой подход позволяет централизованно управлять источниками, легко добавлять новые и безопасно масштабировать систему парсинга.

```
+------------------+        +------------------+
|     Celery       |        |    Scheduler     |
|  Task Worker     |<------>| (every 30 min)   |
+--------+---------+        +------------------+
         |
         v
+------------------+
|  news_collector  |
|  (dynamic tasks) |
+--------+---------+
         |
         v
+------------------+       +------------------+
| Parser Modules   |------>|  Source Enabled? |
| Habr / RBC / TG  |       |    DB Check      |
+--------+---------+       +------------------+
         |
         v
+------------------+
| Validate & Filter|
| (Pydantic & Keywords)|
+--------+---------+
         |
         v
+------------------+
| Deduplicate URLs |
+--------+---------+
         |
         v
+------------------+
|   Database       |
| NewsItem / Source|
+------------------+
```

* **Celery Worker** — выполняет задачу `parse_and_save_news`.
* **Scheduler** — запускает задачу по расписанию.
* **news_collector** — управляет запуском парсеров для активных источников.
* **Parser Modules** — отдельные парсеры для каждого источника (Habr, RBC, Telegram).
* **Validate & Filter** — проверка структуры новости через Pydantic, фильтрация по ключевым словам.
* **Deduplicate URLs** — удаление дубликатов перед сохранением.
* **Database** — хранение источников и новостей в таблицах `Source` и `NewsItem`.

---
