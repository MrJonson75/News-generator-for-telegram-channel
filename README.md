# Как это работает

Проект представляет собой асинхронную систему автоматического сбора новостей, генерации постов для Telegram, тематической классификации и управления контентом через API.

Архитектура построена вокруг **Celery**, **FastAPI**, **SQLAlchemy**, **Redis** и **OpenAI**, что позволяет масштабировать проект, управлять источниками и анализировать данные.

---

## 1. Парсинг новостей и работа с источниками

Система парсинга новостей устроена модульно и управляется через Celery-задачи.

Основная задача `parse_and_save_news` запускается по расписанию (например, каждые 30 минут) и собирает новости с разных источников: Habr, RBC и Telegram.

Источники динамически определяются из базы данных `Source`:

* если `enabled = true` — источник участвует в парсинге
* если `enabled = false` — источник полностью пропускается
* управление источниками доступно через API

При первом запуске, если база пуста, источники автоматически создаются из конфигурации.

Каждая новость:

1. Валидируется через `ParsedNewsSchema` (Pydantic)
2. Фильтруется по ключевым словам
3. Проверяется на дубликаты по URL
4. Сохраняется в таблицу `NewsItem`

```text
                +------------------+        +------------------+
                |     Celery       |        |    Scheduler     |
                |  Task Worker     |<------>| (every 30 min)   |
                +--------+---------+        +------------------+
                |
                v
                +------------------+
                |  news_collector  |
                |  (dynamic tasks) |
                +--------+---------+
                |
                v
                +------------------+       +------------------+
                | Parser Modules   |------>|  Source Enabled? |
                | Habr / RBC / TG  |       |    DB Check      |
                +--------+---------+       +------------------+
                |
                v
                +------------------+
                | Validate & Filter|
                | (Pydantic)       |
                +--------+---------+
                |
                v
                +------------------+
                | Deduplicate URLs |
                +--------+---------+
                |
                v
                +------------------+
                |   Database       |
                | NewsItem / Source|
                +------------------+
```

---

## 2. Генерация постов для Telegram

После сохранения новостей запускается задача `generate_posts`, которая отвечает за создание постов.

### Задача `generate_posts`

Алгоритм работы:

1. Получает новости из БД
2. Проверяет наличие поста для каждой новости:

   * `published` → пропускается
   * `failed` → если превышен лимит попыток — удаляется пост и новость
   * `generated` → допускается перегенерация
3. Генерирует текст через OpenAI
4. Обрабатывает ошибки и лимиты API
5. Создаёт или обновляет пост в таблице `Post`

Задача ограничена по количеству генераций за запуск (`MAX_PER_RUN`) и запускается каждые 10 минут через Celery Beat.

---

## 3. Очистка неудачных постов

Для поддержания чистоты базы данных используется задача:

### `cleanup_old_failed_posts`

Она:

* находит посты со статусом `failed` старше заданного периода
* удаляет их вместе с новостями
* предотвращает накопление мусора

---

## 4. Генерация тегов (ключевых слов)

Для автоматической классификации контента реализована задача:

### `generate_post_keywords`

Назначение:

* семантическая разметка постов
* формирование структуры тегов для поиска и аналитики

Алгоритм:

1. Выбирает посты со статусами `new` и `generated`
2. Пропускает посты без текста или с уже существующими тегами
3. Анализирует текст через OpenAI
4. Создаёт новые Keyword при необходимости
5. Формирует связь многие-ко-многим между Post и Keyword

```text
Post
 └──< post_keywords >── Keyword
```

Задача запускается периодически и масштабируется независимо от генерации постов.

---

## 5. API и управление системой

FastAPI предоставляет полный интерфейс управления системой.

### Работа с постами

* Получение списка постов с фильтрами и пагинацией
* Получение поста по ID
* Изменение статуса поста
* Удаление поста
* Публикация постов
* Ручной запуск генерации

### Управление источниками

Источники можно включать и выключать без перезапуска сервиса:

```text
PATCH /api/sources/{id}
{ "enabled": false }
```

Это позволяет:

* временно отключать проблемные источники
* управлять нагрузкой
* гибко контролировать сбор данных

---

## 6. Управление тегами и аналитика

Реализован отдельный API для работы с тегами:

### Возможности:

* CRUD для тегов (`/api/keywords`)
* Фильтрация постов по тегам
  `GET /api/posts?keyword=python`
* Ручная привязка тегов к постам
  `POST /api/posts/{id}/keywords`
* Статистика по тегам
  `GET /api/keywords/stats`

Пример статистики:

```json
[
  { "word": "python", "post_count": 14 },
  { "word": "ai", "post_count": 9 }
]
```

Это позволяет:

✔ анализировать популярные темы  
✔ строить подборки  
✔ реализовывать поиск  
✔ готовить дашборды  

---

## 7. Health-check и мониторинг

Система имеет встроенные проверки состояния:

### Проверка API и БД

```text
GET /health
```

Проверяет:

* подключение к базе данных  
* доступность OpenAI  

### Проверка Celery и Redis

```text
GET /health/celery
```

Возвращает:

* список активных воркеров  
* активные задачи  
* запланированные задачи  
* очередь сообщений Redis  

---

## Итоговая схема работы

```text
Source (enabled)
   ↓
NewsItem (DB)
   ↓
generate_posts (Celery)
   ↓
Post (DB)
   ↓
generate_post_keywords
   ↓
Keyword (DB)
```

---

## Что обеспечивает система

✔ полностью автоматизированный сбор новостей  
✔ генерацию контента для Telegram  
✔ устойчивость к ошибкам и лимитам  
✔ семантическую классификацию  
✔ удобное API управление  
✔ масштабируемость  
✔ готовность к админ-панели и аналитике  

---
